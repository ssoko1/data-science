# -*- coding: utf-8 -*-
"""DomaciUpdate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EDnkA79bOryIQEaVb-jfJCkRHYQFKq0c
"""

# I DEO: ANALIZA PODATAKA
#importovanje biblioteka
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
import scipy
from scipy import stats
import sklearn
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score
pd.set_option('display.float_format', lambda x: '%.2f' % x)
#ucitavanje i upoznavanje sa bazom
df=pd.read_csv('ChengduPM20100101_20151231.csv')
df.head(7);
df.shape;
df.dtypes
df.info()
df.describe()
df.isnull().sum() / df.shape[0] * 100
#izbacivanje i dopunjavanje podataka
#Ovako smo radili na vezbama
df['PM_US Post'] = df['PM_US Post'].replace(688, np.nan)
df['PM_US Post'] = df['PM_US Post'].replace(685, np.nan)
df['PM_US Post'] = df['PM_US Post'].replace(549, np.nan)
df['PM_US Post'].fillna(df['PM_US Post'].median(), inplace = True)
df['DEWP'].fillna(df['DEWP'].median(), inplace = True)
df['HUMI'].fillna(df['HUMI'].median(), inplace = True)
df['PRES'].fillna(df['PRES'].median(), inplace = True)
df['TEMP'].fillna(df['TEMP'].median(), inplace = True)
df.drop(['cbwd'], inplace=True,axis=1)
df['Iws'].fillna(df['Iws'].median(), inplace = True)
df['precipitation'].fillna(df['precipitation'].median(), inplace = True)
df['Iprec'].fillna(df['Iprec'].median(), inplace = True)
df.drop(['PM_Caotangsi', 'PM_Shahepu'], inplace= True, axis = 1)
df.isnull().sum() / df.shape[0] * 100

df['PM_US Post'].unique()
#arr=df['PM_US Post'].unique()
#l=len(arr)
#count = np.count_nonzero(arr<=70)
#print(count)
#print(l)

df.describe()

#Analiza obelezja
plt.figure(figsize=(10,9))
plt.hist(df.loc[df['year'], 'TEMP'], bins=10, alpha=1, label='temperatura', density=True)
plt.hist(df.loc[df['year'], 'HUMI'], bins=50, alpha=1, label='vlaznost vazduha', density=True)
plt.legend()
plt.show()

sb.pairplot(df)
plt.show()

#8.Analiza obelezja PM25
df.head(100)
df['PM_US Post'].unique()
df['PM_US Post'].describe()

plt.figure(figsize=(10,10))
plt.hist(df.loc[df['PM_US Post'], 'TEMP'], bins=50, alpha=0.5, label='temperatura', density=True)
plt.hist(df.loc[df['PM_US Post'], 'HUMI'], bins=50, alpha=0.5, label='vlaznost vazduha', density=True)
plt.legend()
plt.show()

plt.boxplot(df.loc[df['PM_US Post'],'HUMI'])
plt.ylabel('Vlaznonst vazduha')
plt.xlabel('PM_US Post')
plt.grid()
plt.figure()
plt.boxplot([df.loc[df['PM_US Post'],'DEWP'], df.loc[df['PM_US Post'],'PRES'], df.loc[df['PM_US Post'],'Iws']])
plt.ylabel('')
plt.xlabel('PM US Post')
plt.xticks([1, 2, 3], ["DEWP", "HUMI","Iws"])
plt.grid()

plt.scatter(df['year'], df['PM_US Post'])
plt.show()
plt.scatter(df['PRES'], df['PM_US Post'])
plt.show()

#Korelacija
corr_mat = df.corr()
plt.figure(figsize=(13,13))
sb.heatmap(corr_mat, annot=True)
plt.show()
#df.drop(['No', 'year','month','day','hour','season','precipitation','Iprec'], inplace= True, axis = 1)
#corr_mat = df.corr()
#sb.heatmap(corr_mat, annot=True)
#plt.show()

#df.drop(['No', 'year','month','day','hour','season','precipitation','Iprec'], inplace= True, axis = 1)
#sb.pairplot(df)
#plt.show()

v_sort=np.sort(df['TEMP'])[-1]
i_sort=np.argsort(df['TEMP'])[1]
print(df.index[i_sort],'puta se javlja najcesca temperatura koja iznosi',v_sort)
print(df['HUMI'].mean())
print(df['TEMP'].mean())

# II DEO: LINEARNA REGRESIJA
#Potrebno je 15% nasumično izabranih uzoraka ostaviti kao test skup, 15% kao validacioni a preostalih 70% koristiti za obuku modela.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
x = df.drop(['PM_US Post'], axis=1).copy()
y = df['PM_US Post'].copy()
x_obuka, x_test, y_obuka, y_test=train_test_split(x,y, test_size=0.15, random_state=40)
print(x)
print(y)
print(x_obuka)
print(y_obuka)

def model_evaluation(y, y_predvidjeno, N, d):
    mse = mean_squared_error(y_test, y_predvidjeno)
    mae = mean_absolute_error(y_test, y_predvidjeno)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_predvidjeno)
    r2_adj = 1-(1-r2)*(N-1)/(N-d-1)

    # printing values
    print('Mean squared error: ', mse)
    print('Mean absolute error: ', mae)
    print('Root mean squared error: ', rmse)
    print('R2 score: ', r2)
    print('R2 adjusted score: ', r2_adj)

    # Uporedni prikaz nekoliko pravih i predvidjenih vrednosti
    res=pd.concat([pd.DataFrame(y.values), pd.DataFrame(y_predvidjeno)], axis=1)
    res.columns = ['y', 'y_predvidjeno']
    print(res.head(20))

"""# New Section"""

# Osnovni oblik linearne regresije sa hipotezom y=b0+b1x1+b2x2+...+bnxn
regresioni_model = LinearRegression(fit_intercept=True) # Obuka
regresioni_model.fit(x_obuka, y_obuka)
y_predvidjeno = regresioni_model.predict(x_test)# Testiranje
model_evaluation(y_test, y_predvidjeno, x_obuka.shape[0], x_obuka.shape[1])  # Evaluacija
plt.figure(figsize=(10,5))
plt.bar(range(len(regresioni_model.coef_)),regresioni_model.coef_) # Ilustracija koeficijenata
plt.show()
print("koeficijenti: ", regresioni_model.coef_)

#standardizacija
numeric_feats = [item for item in x.columns if 'PM' not in item]
print(numeric_feats)
dummy_feats = [item for item in x.columns if 'PM' in item]
print(dummy_feats)
scaler = StandardScaler()
scaler.fit(x_obuka[numeric_feats])
#numeric feats
x_obuka_std = pd.DataFrame(scaler.transform(x_obuka[numeric_feats]), columns = numeric_feats)
x_test_std = pd.DataFrame(scaler.transform(x_test[numeric_feats]), columns = numeric_feats)
#dummy feats
x_obuka_std = pd.concat([x_obuka_std, x_obuka[dummy_feats].reset_index(drop=True)], axis=1)
x_test_std = pd.concat([x_test_std, x_test[dummy_feats].reset_index(drop=True)], axis=1)
x_obuka_std.head()

# Linearna regresija sa hipotezom y=b0+b1x1+b2x2+...+bnxn+c1x1x2+c2x1x3+...
poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)
x_inter_obuka = poly.fit_transform(x_obuka_std)
x_inter_test = poly.transform(x_test_std)
# Inicijalizacija
regresioni_model_inter = LinearRegression()
# Obuka modela
regresioni_model_inter.fit(x_inter_obuka, y_obuka)
# Evaluacija
model_evaluation(y_test, y_predvidjeno, x_inter_obuka.shape[0], x_inter_obuka.shape[1])
# Testiranje
y_predvidjeno = regresioni_model_inter.predict(x_inter_test)

# Ilustracija koeficijenata
plt.figure(figsize=(10,5))
plt.bar(range(len(regresioni_model_inter.coef_)),regresioni_model_inter.coef_)
plt.show()
print("koeficijenti: ", regresioni_model_inter.coef_)

#corr_mat = x_obuka[numeric_feats].corr()

#plt.figure(figsize=(12, 9))
#sb.heatmap(corr_mat, annot=True)
#plt.show()

#selekcija unazad
import statsmodels.api as sm
X = sm.add_constant(x_obuka)

model = sm.OLS(y_obuka, X.astype('float')).fit()
model.summary()

#koji je najboji model
# Inicijalizacija
lasso_model = Lasso(alpha=0.01)
# obuka
lasso_model.fit(x_inter_obuka, y_obuka)
# Predict
y_predvidjeni = lasso_model.predict(x_inter_obuka)
# Evaluation
model_evaluation(y_test, y_predvidjeno, x_inter_obuka.shape[0], x_inter_obuka.shape[1])
#ilustracija koeficijenata
plt.figure(figsize=(10,5))
plt.bar(range(len(lasso_model.coef_)),lasso_model.coef_)
plt.show()
print("koeficijenti: ", lasso_model.coef_)

# RIDGE
# Inicijalizacija
ridge_model = Ridge(alpha=5)
# Obuka modela
ridge_model.fit(x_inter_obuka, y_obuka)
# Testiranje
y_predvidjeno = ridge_model.predict(x_inter_test)
# Evaluacija
model_evaluation(y_test, y_predvidjeno, x_inter_obuka.shape[0], x_inter_obuka.shape[1])
# Ilustracija koeficijenata
plt.figure(figsize=(12,7))
plt.bar(range(len(ridge_model.coef_)),ridge_model.coef_)
plt.show()
print("koeficijenti: ", ridge_model.coef_)

plt.figure(figsize=(12,7))
plt.plot(ridge_model.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='pink',label=r'Ridge')
plt.plot(lasso_model.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='yellow',label='Laso')
plt.xlabel('Coefficient Index',fontsize=16)
plt.ylabel('Coefficient Magnitude',fontsize=16)
plt.legend(fontsize=15,loc='best')
plt.show()

#III DEO KNN KLASIFIKATOR
# Napraviti klasifikator koji koristi kNN metodu za klasifikaciju uzoraka u jednu od 3 grupe zagađenja.

"""Prvo je potrebno uzorcima iz date baze dodeliti labele: bezbedno, nebezbedno ili opasno. Uzorcima čija je vrednost koncentracije PM2.5 čestica do 55.4 μg/m3 dodeliti labelu bezbedno, onima čija je vrednost koncentracije PM2.5 čestica od 55.5 μg/m3 do 150.4 μg/m3 dodeliti labelu nebezbedno, dok onima sa vrednošću preko 150.5 μg/m3 dodeliti labelu opasno.

"""

df.shape[1]

#DataFrame.insert(loc, column, value, allow_duplicates=_NoDefault.no_default)
df.insert(14,'Labela','Bezbedno')

df.loc[df['PM_US Post'] >150.4 , 'Labela'] = 'Opasno'
df.loc[(df['PM_US Post'] >55.5) & (df['PM_US Post'] <150.4), 'Labela'] = 'Nebezbedno'
df.loc[df['PM_US Post'] <55.4 , 'Labela'] = 'Bezbedno'

df['Labela'].unique()

df.loc[df['Labela']=='Nebezbedno','Labela']=1
df.loc[df['Labela']=='Bezbedno','Labela']=2
df.loc[df['Labela']=='Opasno','Labela']=3
df['Labela'].unique()

x = df.iloc[:, :14].copy() # obelezja
y = df.iloc[:, 14].copy() # labele

def evaluation_classifier(conf_mat):

    # TODO
    tp = conf_mat[0,0]
    tn = conf_mat[1,1]
    fp = conf_mat[0,1]
    fn = conf_mat[1,0]

    precision = tp/(tp+fp)
    accuracy = (tp+tn)/(tp+tn+fp+fn)
    sensitivity = tp/(tp+fn)
    specificity =tn/(tn+fp)
    F_score = 2*precision*sensitivity/(precision+sensitivity)

    print('precision: ', precision)
    print('accuracy: ', accuracy)
    print('sensitivity/recall: ', sensitivity)
    print('specificity: ', specificity)
    print('F score: ', F_score)

df

from sklearn.model_selection import train_test_split

# TODO

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=11,stratify=y)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV, StratifiedKFold

kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# TODO
parameters = {'metric':['euclidean','hamming'], 'n_neighbors':[1,3,5,9,11,13]}

knn = KNeighborsClassifier()
clf = GridSearchCV(estimator=knn, param_grid=parameters, scoring='accuracy', cv=kfold, refit=True, verbose=3)
clf.fit(X_train, y_train)

print(clf.best_score_)
print(clf.best_params_)

df.shape

y_predvidjeno = clf.predict(x_test)
conf_mat = confusion_matrix(list(y_test), y_predvidjeno, labels=clf.classes_)

disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat,  display_labels=clf.classes_)
disp.plot(cmap="icefire")

plt.show()

evaluation_classifier(conf_mat)

indexes = list(kfold.split(x_obuka, y_obuka))

for metric in ['euclidean','hamming']:

  accuracy = []

  for k in range(1,14):

    tmp_accuracy = []

    for train_index, test_index in indexes:

      Xfold_obuka = x_obuka.iloc[train_index,:]
      yfold_obuka = y_obuka.iloc[train_index]

      Xfold_test = x_obuka.iloc[test_index,:]
      yfold_test = y_obuka.iloc[test_index]

      knn = KNeighborsClassifier(n_neighbors=k, metric=metric)
      knn.fit(Xfold_obuka, yfold_obuka)

      yfold_pred = knn.predict(Xfold_test)
      tmp_accuracy.append(accuracy_score(yfold_test, yfold_pred))

    accuracy.append(np.mean(tmp_accuracy))

  plt.figure(figsize=(12, 6))
  plt.plot(range(1, 14), accuracy, color='red', linestyle='dashed', marker='o', markerfacecolor='pink', markersize=10)
  plt.title('Accuracy for ' + metric)
  plt.xlabel('K Value')
  plt.ylabel('Acc')
  plt.show()